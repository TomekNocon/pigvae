{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import libpysal\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.getLogger(\"lightning\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pigvae.trainer import PLGraphAE\n",
    "from pigvae.synthetic_graphs.hyperparameter import add_arguments\n",
    "from pigvae.synthetic_graphs.data import GraphDataModule, EvalRandomBinomialGraphDataset\n",
    "from pigvae.synthetic_graphs.metrics import Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "import networkx.generators as nxg\n",
    "from networkx.algorithms.shortest_paths.dense import floyd_warshall_numpy\n",
    "from dataclasses import dataclass\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 24\n",
    "PATCH_SIZE = 4\n",
    "class CellDataset(Dataset):\n",
    "\n",
    "    def __init__(self, imgs, targets, channels, img_transform=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.img_transform = img_transform\n",
    "        self.imgs = imgs\n",
    "        self.targets = targets\n",
    "        self.channels = channels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = self.imgs[idx][self.channels, :].to(torch.float32)\n",
    "        target = self.targets[idx]\n",
    "        if self.img_transform:\n",
    "            img = self.img_transform(img.unsqueeze(0))\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "class SplitPatches(nn.Module):\n",
    "    \n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.unfold = torch.nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x -> B c h w\n",
    "        # bs, c, h, w = x.shape\n",
    "        bs, c, h, w = x.shape\n",
    "        \n",
    "        x = self.unfold(x)\n",
    "        # x -> B (c*p*p) L\n",
    "        \n",
    "        # Reshaping into the shape we want\n",
    "        a = x.view(bs, c, self.patch_size, self.patch_size, -1).permute(0, 4, 1, 2, 3)\n",
    "        a = a.view(bs, -1, c *self.patch_size* self.patch_size)\n",
    "        # a -> ( B no.of patches c p p )\n",
    "        return a\n",
    "     \n",
    "train_transform = transforms.Compose([\n",
    "                                    transforms.Resize((SIZE, SIZE)),\n",
    "                                    SplitPatches(PATCH_SIZE)\n",
    "                                     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_dataset = CellDataset(mnist.data.unsqueeze(1), mnist.targets, [0], train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridGraphDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 grid_size: int,\n",
    "                 imgs,\n",
    "                 targets, \n",
    "                 channels, \n",
    "                 img_transform=None,\n",
    "                 sample_per_epoch: int = 10_000\n",
    "        ):\n",
    "        self.grid_size = grid_size\n",
    "        self.sample_per_epoch = sample_per_epoch\n",
    "        self.img_transform = img_transform\n",
    "        self.imgs = imgs[:self.sample_per_epoch]\n",
    "        self.targets = targets[:self.sample_per_epoch]\n",
    "        self.channels = channels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sample_per_epoch\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        g = nx.grid_graph((self.grid_size, self.grid_size))\n",
    "        img = self.imgs[idx][self.channels, :].to(torch.float32)\n",
    "        target = self.targets[idx]\n",
    "        if self.img_transform:\n",
    "            img = self.img_transform(img.unsqueeze(0))\n",
    "        return (g, img, target)\n",
    "\n",
    "class GeometricGraphDataset(Dataset):\n",
    "    def __init__(self, n_min=12, n_max=20, samples_per_epoch=100000, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_min = n_min\n",
    "        self.n_max = n_max\n",
    "        self.samples_per_epoch = samples_per_epoch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples_per_epoch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        n = np.random.randint(low=self.n_min, high=self.n_max)\n",
    "        g = nxg.geometric.random_geometric_graph(n=n, radius=0.5)\n",
    "        return g\n",
    "\n",
    "\n",
    "class BinomialGraphDataset(Dataset):\n",
    "    def __init__(self, n_min=12, n_max=20, p_min=0.4, p_max=0.6,\n",
    "                 samples_per_epoch=100000, pyg=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_min = n_min\n",
    "        self.n_max = n_max\n",
    "        self.p_min = p_min\n",
    "        self.p_max = p_max\n",
    "        self.samples_per_epoch = samples_per_epoch\n",
    "        self.pyg = pyg\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples_per_epoch\n",
    "\n",
    "    def get_largest_subgraph(self, g):\n",
    "        g = g.subgraph(sorted(nx.connected_components(g), key=len, reverse=True)[0])\n",
    "        g = nx.convert_node_labels_to_integers(g, first_label=0)\n",
    "        return g\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        n = np.random.randint(low=self.n_min, high=self.n_max)\n",
    "        if self.p_min == self.p_max:\n",
    "            p = self.p_min\n",
    "        else:\n",
    "            p = np.random.uniform(low=self.p_min, high=self.p_max)\n",
    "        g = nxg.random_graphs.binomial_graph(n, p)\n",
    "        if self.pyg:\n",
    "            g = from_networkx(g)\n",
    "        return g\n",
    "\n",
    "class DenseGraphBatch(Data):\n",
    "    def __init__(self, node_features, edge_features, mask, **kwargs):\n",
    "        super().__init__(**kwargs)  # Call the parent class' constructor (Data)\n",
    "        self.node_features = node_features\n",
    "        self.edge_features = edge_features\n",
    "        self.mask = mask\n",
    "\n",
    "    @classmethod\n",
    "    def from_sparse_graph_list(cls, data_list, labels=True):\n",
    "        if labels:\n",
    "            max_num_nodes = max([graph.number_of_nodes() for graph, _, _ in data_list])\n",
    "        else:\n",
    "            max_num_nodes = max([graph.number_of_nodes() for graph in data_list])\n",
    "        node_features = [] \n",
    "        edge_features = []\n",
    "        mask = []\n",
    "        y = []\n",
    "        props = []\n",
    "        for graph, embedding, label in data_list:\n",
    "            y.append(label)\n",
    "            num_nodes = graph.number_of_nodes()\n",
    "            props.append(torch.Tensor([num_nodes]))\n",
    "            graph.add_nodes_from([i for i in range(num_nodes, max_num_nodes)])\n",
    "            nf = embedding\n",
    "            node_features.append(nf)\n",
    "            # dm = torch.from_numpy(floyd_warshall_numpy(graph)).long()\n",
    "            # dm = torch.clamp(dm, 0, 5).unsqueeze(-1)\n",
    "            # dm = torch.zeros((max_num_nodes, max_num_nodes, num_nodes)).type_as(dm).scatter_(2, dm, 1).float()\n",
    "            # edge_features.append(dm)\n",
    "            mask.append((torch.arange(max_num_nodes) < num_nodes).unsqueeze(0))\n",
    "        node_features = torch.cat(node_features, dim=0)\n",
    "        # edge_features = torch.stack(edge_features, dim=0)\n",
    "        edge_features = torch.tensor(edge_features)\n",
    "        mask = torch.cat(mask, dim=0)\n",
    "        props = torch.cat(props, dim=0)\n",
    "        # Instead of using cls, use Data directly for initialization\n",
    "        batch = DenseGraphBatch(node_features=node_features, edge_features=edge_features, mask=mask, properties=props)\n",
    "        if labels:\n",
    "            batch.y = torch.Tensor(y)\n",
    "        return batch\n",
    "    \n",
    "# class DenseGraphDataLoader(torch.utils.data.DataLoader):\n",
    "#     def __init__(self, dataset, batch_size=1, shuffle=False, labels=True, **kwargs):    \n",
    "#         super().__init__(dataset, batch_size, shuffle,\n",
    "#                          collate_fn=lambda data_list: DenseGraphBatch.from_sparse_graph_list(data_list, labels), **kwargs)\n",
    "\n",
    "def dense_graph_collate_fn(data_list):\n",
    "    return DenseGraphBatch.from_sparse_graph_list(data_list)\n",
    "\n",
    "\n",
    "class DenseGraphDataLoader(torch.utils.data.DataLoader):\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False, labels=True, **kwargs):\n",
    "        self.labels = labels\n",
    "        super().__init__(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            collate_fn=dense_graph_collate_fn,  # Directly pass the standalone function\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "class GraphDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "            self, \n",
    "            graph_family,\n",
    "            graph_kwargs=None, \n",
    "            samples_per_epoch=100000, \n",
    "            batch_size=32,\n",
    "            distributed_sampler=True, \n",
    "            num_workers=1\n",
    "        ):\n",
    "        super().__init__()\n",
    "        if graph_kwargs is None:\n",
    "            graph_kwargs = {}\n",
    "        self.graph_family = graph_family\n",
    "        self.graph_kwargs = graph_kwargs\n",
    "        self.samples_per_epoch = samples_per_epoch\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        self.distributed_sampler = distributed_sampler\n",
    "        self.train_dataset = None\n",
    "        self.eval_dataset = None\n",
    "        self.train_sampler = None\n",
    "        self.eval_sampler = None\n",
    "\n",
    "    def make_dataset(self, samples_per_epoch):\n",
    "        if self.graph_family == \"binomial\":\n",
    "            ds = BinomialGraphDataset(samples_per_epoch=samples_per_epoch, **self.graph_kwargs)\n",
    "        elif self.graph_family == 'grid':\n",
    "            ds = GridGraphDataset(sample_per_epoch=samples_per_epoch, **self.graph_kwargs) \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return ds\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        self.train_dataset = self.make_dataset(samples_per_epoch=self.samples_per_epoch)\n",
    "        if self.distributed_sampler:\n",
    "            train_sampler = DistributedSampler(\n",
    "                dataset=self.train_dataset,\n",
    "                shuffle=False\n",
    "            )\n",
    "        else:\n",
    "            train_sampler = None\n",
    "        \n",
    "        return DenseGraphDataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            sampler=train_sampler,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        self.eval_dataset = self.make_dataset(samples_per_epoch=4096)\n",
    "        if self.distributed_sampler:\n",
    "            eval_sampler = DistributedSampler(\n",
    "                dataset=self.eval_dataset,\n",
    "                shuffle=False\n",
    "            )\n",
    "        else:\n",
    "            eval_sampler = None\n",
    "        return DenseGraphDataLoader(\n",
    "            dataset=self.eval_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            sampler=eval_sampler,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_kwargs_binomial = {\n",
    "        \"n_min\": 6,\n",
    "        \"n_max\": 8,\n",
    "        \"m_min\": 1,\n",
    "        \"m_max\": 5,\n",
    "        \"p_min\": 0.4,\n",
    "        \"p_max\": 0.6\n",
    "    }\n",
    "\n",
    "graph_kwargs_grid = {\n",
    "        \"grid_size\": 6,\n",
    "        \"imgs\": mnist.data.unsqueeze(1),\n",
    "        \"targets\": mnist.targets,\n",
    "        \"img_transform\": train_transform,\n",
    "        \"channels\": [0]\n",
    "}\n",
    "\n",
    "\n",
    "graph_family_binomial = \"binomial\"\n",
    "graph_family_grid = \"grid\"\n",
    "\n",
    "\n",
    "datamodule = GraphDataModule(\n",
    "        graph_family=graph_family_grid,\n",
    "        graph_kwargs=graph_kwargs_grid,\n",
    "        batch_size=32,\n",
    "        num_workers=0,\n",
    "        samples_per_epoch=1000,\n",
    "        distributed_sampler=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datamodule.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [el for el in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as scs\n",
    "import numpy as np\n",
    "import torch\n",
    "from libpysal.weights import lat2W\n",
    "\n",
    "\n",
    "class LaplacianGridEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        grid_size: int, \n",
    "        out_dim: int, \n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        # Define the fully connected layer\n",
    "        self.fc1 = nn.Linear(grid_size**2, out_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "       \n",
    "        x = x.transpose(-2, -1)\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "    \n",
    "    @classmethod\n",
    "    def get_graph_laplacian(cls, A):\n",
    "        D = np.diag(A.sum(axis=0))\n",
    "        L = D - A\n",
    "        return L\n",
    "\n",
    "# Define grid size\n",
    "grid_size = 3  # Example\n",
    "\n",
    "# Precompute adjacency matrix\n",
    "A = lat2W(grid_size, grid_size, rook=True).full()[0]\n",
    "A_sparse = scs.csr_matrix(A)  # Sparse format for efficient Laplacian computation\n",
    "\n",
    "# Precompute Laplacian\n",
    "L = LaplacianGridEmbedding.get_graph_laplacian(A)\n",
    "\n",
    "# Precompute eigen decomposition\n",
    "eigenvals, eigenvecs = np.linalg.eigh(L)\n",
    "sorted_eigenvecs = eigenvecs[:, np.argsort(eigenvals)]\n",
    "sorted_eigenvecs = torch.tensor(sorted_eigenvecs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectralEmbeddings = LaplacianGridEmbedding(\n",
    "    grid_size=grid_size, \n",
    "    out_dim=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 16])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectralEmbeddings(sorted_eigenvecs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_tensor(a, bs, c, h, w, patch_size):\n",
    "    # Step 1: Reshape a to match the patch grid layout\n",
    "    a = a.view(bs, -1, c, patch_size, patch_size)\n",
    "    # a -> (B, num_patches, C, patch_size, patch_size)\n",
    "    \n",
    "    # Step 2: Reshape back to (B, C, H, W) by folding the patches\n",
    "    # Calculate the grid size (L) which is the number of patches in each row and column\n",
    "    grid_size = int(a.size(1) ** 0.5)  # Assumes square grid (height = width for the patches)\n",
    "    \n",
    "    # Unfold back into the original image size\n",
    "    a = a.view(bs, grid_size, grid_size, c, patch_size, patch_size)\n",
    "    # a -> (B, grid_size, grid_size, C, patch_size, patch_size)\n",
    "    \n",
    "    # Step 3: Permute and reshape to get back to the image format (B, C, H, W)\n",
    "    x_reconstructed = a.permute(0, 3, 1, 4, 2, 5).contiguous()\n",
    "    # x_reconstructed -> (B, C, grid_size, patch_size, grid_size, patch_size)\n",
    "    \n",
    "    x_reconstructed = x_reconstructed.view(bs, c, h, w)\n",
    "    # x_reconstructed -> (B, C, H, W)\n",
    "    \n",
    "    return x_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = restore_tensor(batches[0].node_features, 32, 1, 24, 24, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAYABgBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APCl025bSZNTCf6KkwgLZ/jIJA/IVUrT1jRpdGFgJ3zJd2qXOzbgoGJwD+AB/Gun0o6Vqnw7XRm1ex068XUDcSm6DDeu3C4IB96j0vwx4Ym1yz09/EE2oyzzJGIrG1Kq2T/fcjA/A1T+JGoJqPj7VWix5EEn2WHByNkYCD89ufxrla2PCupwaN4r0vUrnd5FtcLJJtGTgHnFVtbube812/ubTd9nmuHePcMHaWJGa//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAAAAADFHGIkAAAA3ElEQVR4nGNgGAig0yjEwMDAwMTAwCDnxIMkYSrHAZMwCONHiLPocv6BSejJMiIkDLxuvoJKcPAzI5nkJ3iNASohp86GEGcXY7wOk5CSffsbLmFj9uEdxC4GBlbWm98YGJiYmZjYpJ3CNLvewCT+/xdX+cwnL6vCbvzrKSvjsV8wiZcXbPX+cHG/enFv0uWXNZqP/8EkLjeZcDEwvL354DsDg6XR3W8MMAmG27fhdgsIbPvAAHMVKnjxC7sEoygrdon/vMw4jFLgxCrx6TPcTFQJITuG3V/RDSESAABALzV06UoFpQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=24x24>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.fromarray(np.array(x[2].reshape(24, 24), dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'num_epochs': 10, 'num_eval_samples': 8192, 'eval_freq': 1000, 'save_dir': '/Users/tomeknocon/MIM/Master_Thesis/PIGVAE/pigvae/synthetic_graphs', 'precision': 32, 'progress_bar': True, 'test': False, 'resume_ckpt': '', 'batch_size': 32, 'lr': 5e-05, 'kld_loss_scale': 0.001, 'perm_loss_scale': 0.5, 'property_loss_scale': 0.1, 'vae': True, 'num_node_features': 36, 'num_edge_features': 36, 'emb_dim': 64, 'graph_encoder_hidden_dim': 256, 'graph_encoder_k_dim': 64, 'graph_encoder_v_dim': 64, 'graph_encoder_num_heads': 16, 'graph_encoder_ppf_hidden_dim': 1024, 'graph_encoder_num_layers': 16, 'graph_decoder_hidden_dim': 256, 'graph_decoder_k_dim': 64, 'graph_decoder_v_dim': 64, 'graph_decoder_num_heads': 16, 'graph_decoder_ppf_hidden_dim': 1024, 'graph_decoder_pos_emb_dim': 64, 'graph_decoder_num_layers': 16, 'property_predictor_hidden_dim': 256, 'num_properties': 1, 'num_workers': 1, 'shuffle': 1, 'graph_family': 'grid', 'n_min': 12, 'n_max': 20, 'p_min': 0.4, 'p_max': 0.6, 'm_min': 1, 'm_max': 5}\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "import os\n",
    "\n",
    "DEFAULT_SAVE_DIR = os.path.join(os.getcwd())\n",
    "\n",
    "@dataclass\n",
    "class Params:\n",
    "    id: int = 0\n",
    "    num_epochs: int = 10\n",
    "    num_eval_samples: int = 8192\n",
    "    eval_freq: int = 1000\n",
    "    save_dir: str = DEFAULT_SAVE_DIR\n",
    "    precision: int = 32\n",
    "    progress_bar: bool = True\n",
    "    test: bool = False\n",
    "    resume_ckpt: str = \"\"\n",
    "    batch_size: int = 32\n",
    "    lr: float = 0.00005\n",
    "    kld_loss_scale: float = 0.001\n",
    "    perm_loss_scale: float = 0.5\n",
    "    property_loss_scale: float = 0.1\n",
    "    vae: bool = True\n",
    "    num_node_features: int = 36\n",
    "    num_edge_features: int = 36\n",
    "    emb_dim: int = 64\n",
    "    graph_encoder_hidden_dim: int = 256\n",
    "    graph_encoder_k_dim: int = 64\n",
    "    graph_encoder_v_dim: int = 64\n",
    "    graph_encoder_num_heads: int = 16\n",
    "    graph_encoder_ppf_hidden_dim: int = 1024\n",
    "    graph_encoder_num_layers: int = 16\n",
    "    graph_decoder_hidden_dim: int = 256\n",
    "    graph_decoder_k_dim: int = 64\n",
    "    graph_decoder_v_dim: int = 64\n",
    "    graph_decoder_num_heads: int = 16\n",
    "    graph_decoder_ppf_hidden_dim: int = 1024\n",
    "    graph_decoder_pos_emb_dim: int = 64\n",
    "    graph_decoder_num_layers: int = 16\n",
    "    property_predictor_hidden_dim: int = 256\n",
    "    num_properties: int = 1\n",
    "    num_workers: int = 1\n",
    "    shuffle: int = 1\n",
    "    graph_family: str = \"grid\"\n",
    "    n_min: int = 12\n",
    "    n_max: int = 20\n",
    "    p_min: float = 0.4\n",
    "    p_max: float = 0.6\n",
    "    m_min: int = 1\n",
    "    m_max: int = 5\n",
    "\n",
    "# Example usage\n",
    "hparams = Params()\n",
    "\n",
    "# Convert to dictionary\n",
    "params_dict = asdict(hparams)\n",
    "\n",
    "print(params_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = Critic\n",
    "model = PLGraphAE(params_dict, critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type    | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | graph_ae | GraphAE | 50.7 M | train\n",
      "1 | critic   | Critic  | 0      | train\n",
      "---------------------------------------------\n",
      "50.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "50.7 M    Total params\n",
      "202.743   Total estimated model params size (MB)\n",
      "487       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/tomeknocon/opt/anaconda3/envs/pigvae/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/tomeknocon/opt/anaconda3/envs/pigvae/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'GridGraphDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 9619) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/multiprocessing/queues.py:108\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m--> 108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 27\u001b[0m\n\u001b[1;32m     12\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m GraphDataModule(\n\u001b[1;32m     13\u001b[0m     graph_family\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39mgraph_family,\n\u001b[1;32m     14\u001b[0m     graph_kwargs\u001b[38;5;241m=\u001b[39mgraph_kwargs_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     distributed_sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     21\u001b[0m     val_check_interval\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39meval_freq \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hparams\u001b[38;5;241m.\u001b[39mtest \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     22\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39mnum_epochs,\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1023\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1052\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1049\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/loops/evaluation_loop.py:128\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     batch, batch_idx, dataloader_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_dataloader_idx \u001b[38;5;241m!=\u001b[39m dataloader_idx:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# the dataloader has changed, notify the logger connector\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/loops/fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/loops/fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/utilities/combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ITERATOR_RETURN:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/pytorch_lightning/utilities/combined_loader.py:142\u001b[0m, in \u001b[0;36m_Sequential.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# try the next iterator\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_next_iterator()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pigvae/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 9619) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "lr_logger = LearningRateMonitor()\n",
    "tb_logger = TensorBoardLogger(hparams.save_dir + \"/run{}/\".format(hparams.id))\n",
    "critic = Critic\n",
    "model = PLGraphAE(params_dict, critic)\n",
    "graph_kwargs_grid = {\n",
    "        \"grid_size\": 6,\n",
    "        \"imgs\": mnist.data.unsqueeze(1),\n",
    "        \"targets\": mnist.targets,\n",
    "        \"img_transform\": train_transform,\n",
    "        \"channels\": [0]\n",
    "}\n",
    "datamodule = GraphDataModule(\n",
    "    graph_family=hparams.graph_family,\n",
    "    graph_kwargs=graph_kwargs_grid,\n",
    "    batch_size=hparams.batch_size,\n",
    "    num_workers=hparams.num_workers,\n",
    "    samples_per_epoch=10_000,\n",
    "    distributed_sampler=False\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    val_check_interval=hparams.eval_freq if not hparams.test else 100,\n",
    "    accelerator=\"cpu\",\n",
    "    gradient_clip_val=0.1,\n",
    "    precision=hparams.precision,\n",
    "    max_epochs=hparams.num_epochs,\n",
    ")\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule = GraphDataModule(\n",
    "#         graph_family=graph_family,\n",
    "#         graph_kwargs=graph_kwargs,\n",
    "#         batch_size=32,\n",
    "#         num_workers=0,\n",
    "#         samples_per_epoch=1000,\n",
    "#         distributed_sampler=None\n",
    "#     )\n",
    "# trainer = pl.Trainer(\n",
    "#     val_check_interval=hparams.eval_freq if not hparams.test else 100,\n",
    "#     accelerator=\"cpu\",\n",
    "#     gradient_clip_val=0.1,\n",
    "#     precision=hparams.precision,\n",
    "#     max_epochs=hparams.num_epochs,\n",
    "# )\n",
    "# trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseGraphBatch1(Data):\n",
    "    def __init__(self, node_features, edge_features, mask):\n",
    "        self.node_features = node_features\n",
    "        self.edge_features = edge_features\n",
    "        self.mask = mask\n",
    "\n",
    "    # @classmethod\n",
    "    # def from_sparse_graph_list(cls, data_list, labels=False):\n",
    "    #     if labels:\n",
    "    #         max_num_nodes = max([graph.number_of_nodes() for graph, label in data_list])\n",
    "    #     else:\n",
    "    #         max_num_nodes = max([graph.number_of_nodes() for graph in data_list])\n",
    "    #     node_features = []\n",
    "    #     edge_features = []\n",
    "    #     mask = []\n",
    "    #     y = []\n",
    "    #     props = []\n",
    "    #     for data in data_list:\n",
    "    #         if labels:\n",
    "    #             graph, label = data\n",
    "    #             y.append(label)\n",
    "    #         else:\n",
    "    #             graph = data\n",
    "    #         num_nodes = graph.number_of_nodes()\n",
    "    #         props.append(torch.Tensor([num_nodes]))\n",
    "    #         graph.add_nodes_from([i for i in range(num_nodes, max_num_nodes)])\n",
    "    #         nf = torch.ones(max_num_nodes, 1)\n",
    "    #         node_features.append(nf.unsqueeze(0))\n",
    "    #         dm = torch.from_numpy(floyd_warshall_numpy(graph)).long()\n",
    "    #         dm = torch.clamp(dm, 0, 5).unsqueeze(-1)\n",
    "    #         num_nodes = dm.size(1)\n",
    "    #         dm = torch.zeros((num_nodes, num_nodes, 6)).type_as(dm).scatter_(2, dm, 1).float()\n",
    "    #         edge_features.append(dm)\n",
    "    #         mask.append((torch.arange(max_num_nodes) < num_nodes).unsqueeze(0))\n",
    "    #     node_features = torch.cat(node_features, dim=0)\n",
    "    #     edge_features = torch.stack(edge_features, dim=0)\n",
    "    #     mask = torch.cat(mask, dim=0)\n",
    "    #     props = torch.cat(props, dim=0)\n",
    "    #     batch = cls(node_features=node_features, edge_features=edge_features, mask=mask, properties=props)\n",
    "    #     if labels:\n",
    "    #         batch.y = torch.Tensor(y)\n",
    "    #     return batch\n",
    "\n",
    "    # def __repr__(self):\n",
    "    #     repr_list = [\"{}={}\".format(key, list(value.shape)) for key, value in self.__dict__.items()]\n",
    "    #     return \"DenseGraphBatch({})\".format(\", \".join(repr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "CIRCLE_SIZE = 24\n",
    "\n",
    "\n",
    "def get_circle_graph(size=CIRCLE_SIZE):\n",
    "    circle = np.zeros((size, size))\n",
    "    for i in range(size):\n",
    "        circle[i, (i + 1) % size] = 1\n",
    "        circle[i, (i - 1) % size] = 1\n",
    "    return circle\n",
    "\n",
    "\n",
    "def get_graph_laplacian(graph):\n",
    "    d = np.diag(graph.sum(axis=0))\n",
    "    return d - graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eigen(eigen):\n",
    "    n = np.sqrt(len(eigen))\n",
    "    circle_points = np.meshgrid(np.arange(n), np.arange(n), indexing='ij')\n",
    "    eigen_std = eigen.std()\n",
    "    vmin=eigen.min() - 1e-3\n",
    "    vmax=eigen.max() + 1e-3\n",
    "    plt.scatter(\n",
    "        x=circle_points[0],\n",
    "        y=circle_points[1],\n",
    "        c=eigen,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        cmap='seismic',\n",
    "        s=100,\n",
    "    )\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "def plot_eigens(eigens, eigenvals):\n",
    "    plot_size = math.ceil(eigens.shape[0] ** 0.5)\n",
    "    plt.figure(figsize=(5 * plot_size, 5 * plot_size))\n",
    "    for eigen_nb, eigen_ in enumerate(eigens.T):\n",
    "        plt.subplot(plot_size, plot_size, eigen_nb + 1)\n",
    "        plot_eigen(eigen_)\n",
    "        plt.title(f'Eigen {eigen_nb}: {round(eigenvals[eigen_nb], 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvals, eigenvecs = np.linalg.eig(L)\n",
    "sorted_eigenvecs = eigenvecs[:, eigenvals.argsort()]\n",
    "sorted_eigenvals = eigenvals[eigenvals.argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvals, eigenvecs = np.linalg.eig(L)\n",
    "sorted_eigenvecs = eigenvecs[:, eigenvals.argsort()]\n",
    "sorted_eigenvals = eigenvals[eigenvals.argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_eigenvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_eigenvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [...]  # List of edges in the grid graph\n",
    "k = 36\n",
    "edge_features_1 = {}\n",
    "grid = np.meshgrid(np.arange(6), np.arange(6))\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        feature = eigenvecs[:, :k][:, i] - eigenvecs[:, :k][:, j]  # Use first k eigenvectors\n",
    "        edge_features_1[(i, j)] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_features_tensor = eigenvecs[:, :k][:, None, :] - eigenvecs[:, :k][None, :, :]  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pigvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
